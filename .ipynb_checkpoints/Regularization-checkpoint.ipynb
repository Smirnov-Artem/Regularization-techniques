{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Y1\", \"X3_dummy\", \"X4\", \"X5\", \"X6\", \"X7\", \"X8\", \"X9\", \"X10\", \"X11\", \"X12\", \"X13\", \"X14_dummy\", \"logX15\", \"logX16\", \"X17\", \"X18\", \"X19\", \"logX20\", \"logX21\", \"X22\", \"X23_dummy\", \"X24_dummy\", \"X25\", \"X26\", \"X27\", \"X28\", \"X29\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.../alpha_alpha.txt', sep=\" \", header=None, names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into test and train sets\n",
    "split = train_test_split(df, test_size=0.25, random_state=42)\n",
    "(trainAttrX, testAttrX) = split\n",
    "trainY = trainAttrX[\"Y1\"]\n",
    "testY = testAttrX[\"Y1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(trainY).to_excel('trainY_log_scale.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to standardize our data only after splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAttrX = trainAttrX.drop('Y1', axis=1)\n",
    "#trainAttrX = trainAttrX.drop('No', axis=1)\n",
    "testAttrX = testAttrX.drop('Y1', axis=1)\n",
    "#testAttrX = testAttrX.drop('No', axis=1)\n",
    "\n",
    "cs = StandardScaler()\n",
    "trainAttrX = cs.fit_transform(trainAttrX)\n",
    "testAttrX = cs.transform(testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix alpha for Ridge, we should not normalize data after standardization, interception is true\n",
    "ridgeReg = Ridge(alpha=1, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function can help us to find the optimal alpha\n",
    "for a in alphas:\n",
    "    model_ridge = Ridge(alpha=a).fit(trainAttrX,trainY)   \n",
    "    score_ridge = model_ridge.score(trainAttrX,trainY)\n",
    "    pred_y = model_ridge.predict(trainAttrX)\n",
    "    mse = mean_squared_error(trainY, pred_y)   \n",
    "    print(\"Alpha:{0:.4f}, R2:{1:.2f}, MSE:{2:.2f}, RMSE:{3:.2f}\"\n",
    "       .format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeReg.fit(trainAttrX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ridge = ridgeReg.predict(testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ridge = np.mean((test_ridge - testY)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeReg.score(testAttrX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeReg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(ridgeReg.coef_, predictors).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "predictors = cols[1:]\n",
    "\n",
    "coef = Series(ridgeReg.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')\n",
    "#plt.savefig('ridge.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show coefficients of the regression\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ridge = ridgeReg.predict(trainAttrX)\n",
    "pd.DataFrame(train_ridge).to_excel('train_ridge.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ridge = ridgeReg.predict(testAttrX)\n",
    "pd.DataFrame(test_ridge).to_excel('test_ridge.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same fo lasso, alpha is fixed too\n",
    "lassoReg = Lasso(alpha=0.1, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = lassoReg.fit(trainAttrX,trainY)\n",
    "lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alphas:\n",
    "    model_lasso = Lasso(alpha=a).fit(trainAttrX,trainY)   \n",
    "    score_lasso = model_lasso.score(trainAttrX,trainY)\n",
    "    pred_y = model_lasso.predict(trainAttrX)\n",
    "    mse = mean_squared_error(trainY, pred_y)   \n",
    "    print(\"Alpha:{0:.4f}, R2:{1:.2f}, MSE:{2:.2f}, RMSE:{3:.2f}\"\n",
    "       .format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lasso = lassoReg.predict(testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lasso = np.mean((test_lasso - testY)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoReg.score(testAttrX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(lassoReg.coef_, predictors).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "predictors = cols[1:]\n",
    "\n",
    "coef = Series(lassoReg.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lasso = lassoReg.predict(trainAttrX)\n",
    "pd.DataFrame(train_lasso).to_excel('train_lasso.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lasso = lassoReg.predict(testAttrX)\n",
    "pd.DataFrame(test_lasso).to_excel('test_lasso.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "t1 = time.time()\n",
    "model_bic.fit(testAttrX, testY)\n",
    "t_bic = time.time() - t1\n",
    "alpha_bic_ = model_bic.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this model we don't fix alpha, optimal alpha is output of the function\n",
    "\n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "t1 = time.time()\n",
    "model_bic.fit(trainAttrX, trainY)\n",
    "t_bic = time.time() - t1\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(trainAttrX, trainY)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_ + EPSILON\n",
    "    alphas_ = model.alphas_ + EPSILON\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color,\n",
    "             linewidth=3, label='%s criterion' % name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=3,\n",
    "                label='alpha: %s estimate' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'b')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'r')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection (training time %.3fs)'\n",
    "          % t_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bic.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(model_aic.criterion_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aic.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(model_bic.criterion_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(model_bic.coef_, predictors).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lars = model_bic.predict(testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_new = pd.Series(model_bic.coef_, predictors).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "predictors = cols[1:]\n",
    "\n",
    "coef_new = Series(model_bic.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_lars = np.mean((test_lars - testY)**2)\n",
    "mse_lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lars = model_bic.predict(trainAttrX)\n",
    "pd.DataFrame(train_lars).to_excel('train_lars.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lars = model_bic.predict(testAttrX)\n",
    "pd.DataFrame(test_lars).to_excel('test_lars.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet,ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic=ElasticNet(alpha=0.01).fit(trainAttrX, trainY)\n",
    "ypred = elastic.predict(testAttrX)\n",
    "score = elastic.score(testAttrX, testY)\n",
    "mse = mean_squared_error(testY, ypred)\n",
    "print(\"R2:{0:.3f}, MSE:{1:.2f}, RMSE:{2:.2f}\"\n",
    "      .format(score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 0.7, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in alphas:\n",
    "    model = ElasticNet(alpha=a).fit(trainAttrX,trainY)   \n",
    "    score = model.score(trainAttrX,trainY)\n",
    "    pred_y = model.predict(trainAttrX)\n",
    "    mse = mean_squared_error(trainY, pred_y)   \n",
    "    print(\"Alpha:{0:.4f}, R2:{1:.2f}, MSE:{2:.2f}, RMSE:{3:.2f}\"\n",
    "       .format(a, score, mse, np.sqrt(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ax = range(len(testAttrX))\n",
    "plt.scatter(x_ax, testY, s=5, color=\"blue\", label=\"original\")\n",
    "plt.plot(x_ax, ypred, lw=0.8, color=\"red\", label=\"predicted\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_EN = pd.Series(elastic.coef_, predictors).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_EN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the magnitude of coefficients\n",
    "\n",
    "predictors = cols[1:]\n",
    "\n",
    "coef_EN = Series(elastic.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en = elastic.predict(testAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_en = np.mean((test_en - testY)**2)\n",
    "mse_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = elastic.predict(trainAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_en).to_excel('train_en.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_en = elastic.predict(testAttrX)\n",
    "pd.DataFrame(test_en).to_excel('test_en.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LassoLarsIC.alpha_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
